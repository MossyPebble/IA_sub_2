{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab에서 실행할 경우 사용\n",
    "\n",
    "# drive 마운트\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 파일 경로 지정\n",
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive/Workspace/IA_sub_2')\n",
    "print(sys.path)\n",
    "\n",
    "import os\n",
    "os.chdir('/content/drive/MyDrive/Workspace/IA_sub_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로컬에서 실행할 경우 사용\n",
    "\n",
    "# 파일 경로 지정\n",
    "import sys, os\n",
    "from IPython import get_ipython\n",
    "notebook_dir = os.path.dirname(os.path.abspath(get_ipython().run_line_magic('pwd', '')))\n",
    "sys.path.append(notebook_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] columns are dropped.\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "import pandas as pd\n",
    "from lib import data_preprocessor\n",
    "\n",
    "# 데이터 csv를 dataFrame으로 변환\n",
    "# 데이터 경로는 ../data에 있는 data라는 이름이 들어간 csv 파일로 가정\n",
    "path = '../data'\n",
    "dir = os.listdir(path)\n",
    "for file in dir:\n",
    "    if 'data' in file:\n",
    "        data = file\n",
    "        break\n",
    "df = data_preprocessor.transform_verilog_results_to_DataFrame(path + '/' + data)\n",
    "normal_df, data_min, data_max = data_preprocessor.normalize_DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       phig       cit        u0        ua        eu    etamob        up  \\\n",
      "0  0.500000  0.500001  0.500003  0.499997  0.500002  0.500002  0.500001   \n",
      "1  0.410751  0.511724  0.453817  0.359631  0.202639  0.255747  0.472937   \n",
      "2  0.745142  0.358529  0.236329  0.538958  0.849749  0.157734  0.099613   \n",
      "3  0.853537  0.657667  0.574691  0.225739  0.038224  0.912242  0.206496   \n",
      "4  0.763113  0.319106  0.961664  0.397547  0.107565  0.796154  0.351070   \n",
      "\n",
      "       rdsw        i0       i62  \n",
      "0  0.500001  0.222644  0.574051  \n",
      "1  0.001458  0.263669  0.734298  \n",
      "2  0.288490  0.079474  0.477440  \n",
      "3  0.799905  0.115181  0.570204  \n",
      "4  0.309568  0.176218  0.733957   \n",
      "\n",
      "phig      4.456108e+00\n",
      "cit       1.152020e-04\n",
      "u0        1.434403e-02\n",
      "ua        1.780053e-01\n",
      "eu        2.636023e-01\n",
      "etamob    2.952038e+00\n",
      "up        4.020056e-10\n",
      "rdsw      3.850809e+01\n",
      "i0        8.542756e-13\n",
      "i62       4.507874e-05\n",
      "dtype: float64 \n",
      "\n",
      "phig      4.500892e+00\n",
      "cit       4.607970e-04\n",
      "u0        5.737568e-02\n",
      "ua        7.119981e-01\n",
      "eu        1.054394e+00\n",
      "etamob    1.180792e+01\n",
      "up        1.607992e-09\n",
      "rdsw      1.540316e+02\n",
      "i0        1.766845e-11\n",
      "i62       1.438342e-04\n",
      "dtype: float64 \n",
      "\n",
      "(100001, 10)\n"
     ]
    }
   ],
   "source": [
    "# 데이터가 올바르게 로드되었는지 확인\n",
    "print(normal_df.head(), '\\n')\n",
    "print(data_min, '\\n')\n",
    "print(data_max, '\\n')\n",
    "print(normal_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 80%의 학습 데이터와 20%의 테스트 데이터로 분할\n",
    "train_df, test_df = normal_df[:int(len(normal_df)*0.8)], normal_df[int(len(normal_df)*0.8):]\n",
    "\n",
    "# 데이터를 학습 데이터와 레이블로 분할하여 dataLoader로 변환\n",
    "input_feature = ['i0', 'i62']\n",
    "output_feature = ['phig', 'cit', 'u0', 'ua', 'eu', 'etamob', 'up', 'rdsw']\n",
    "train_dl = data_preprocessor.transform_DataFrame_to_DataLoader(train_df[input_feature], train_df[output_feature], 128, True)\n",
    "\n",
    "# 테스트 데이터도 동일하게 변환\n",
    "test_dl = data_preprocessor.transform_DataFrame_to_DataLoader(test_df[input_feature], test_df[output_feature], 1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN 모델 학습\n",
    "\n",
    "from lib import model_training\n",
    "import lib.ANN as ANN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "ann_model = ANN.ANN(input_feature.__len__(), output_feature.__len__())\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(ann_model.parameters(), lr=1e-5)\n",
    "ann_model, train_loss, val_loss = model_training.train_model(\n",
    "    ann_model, \n",
    "    train_dl, \n",
    "    100,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    test_dl,\n",
    "    1,\n",
    "    True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn을 이용하기 위한 데이터 변환\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 데이터를 학습 데이터와 레이블로 분할\n",
    "features = normal_df[input_feature]\n",
    "labels = normal_df[output_feature]\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터로 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest 모델 학습\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# 랜덤 포레스트 회귀 모델 생성\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)  # n_estimators는 트리 개수, 조정 가능\n",
    "\n",
    "# 모델 학습\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터로 예측\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# 모델 평가 (MSE 사용)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBM 모델 학습\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "# GBM 모델 생성\n",
    "gbm_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "multi_output_gbm_model = MultiOutputRegressor(gbm_model)\n",
    "\n",
    "# 모델 학습\n",
    "multi_output_gbm_model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터로 예측\n",
    "y_pred = multi_output_gbm_model.predict(X_test)\n",
    "\n",
    "# 모델 평가 (MSE 사용)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-D CNN 모델 학습\n",
    "\n",
    "from lib import model_training\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from lib.CNN import CNN\n",
    "\n",
    "cnn_model = CNN(input_feature.__len__(), output_feature.__len__())\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(cnn_model.parameters(), lr=1e-5)\n",
    "cnn_model, train_loss, val_loss = model_training.train_model(\n",
    "    cnn_model, \n",
    "    train_dl, \n",
    "    100,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    test_dl,\n",
    "    1,\n",
    "    True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPR 모델 학습\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "# GPR 모델 생성\n",
    "gpr_model = GaussianProcessRegressor(kernel=RBF() + WhiteKernel(), random_state=42)\n",
    "multi_output_gpr_model = MultiOutputRegressor(gpr_model)\n",
    "\n",
    "# 모델 학습\n",
    "multi_output_gpr_model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터로 예측\n",
    "y_pred = multi_output_gpr_model.predict(X_test)\n",
    "\n",
    "# 모델 평가 (MSE 사용)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "import joblib\n",
    "\n",
    "joblib.dump(rf_model, 'Model/random_forest_model.pkl')\n",
    "\n",
    "# weight dict 형태로 저장\n",
    "torch.save(cnn_model.state_dict(), 'Model/cnn_model_weights.pt')\n",
    "torch.save(ann_model.state_dict(), 'Model/ann_model_weights.pt')\n",
    "joblib.dump(multi_output_gbm_model, 'Model/gbm_model.pkl')\n",
    "joblib.dump(multi_output_gpr_model, 'Model/gpr_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
