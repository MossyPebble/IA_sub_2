{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab에서 실행할 경우 사용\n",
    "\n",
    "# drive 마운트\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 파일 경로 지정\n",
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive/Workspace/IA_sub_2')\n",
    "print(sys.path)\n",
    "\n",
    "import os\n",
    "os.chdir('/content/drive/MyDrive/Workspace/IA_sub_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로컬에서 실행할 경우 사용\n",
    "\n",
    "# 파일 경로 지정\n",
    "import sys, os\n",
    "from IPython import get_ipython\n",
    "notebook_dir = os.path.dirname(os.path.abspath(get_ipython().run_line_magic('pwd', '')))\n",
    "sys.path.append(notebook_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] columns are dropped.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['index', 'vth0', 'cit', 'mob_u0', 'mob_ua', 'mob_ub', 'mob_ug',\n",
       "       'nfactor', 'delta', 'kg',\n",
       "       ...\n",
       "       'c51_low', 'c52_low', 'c53_low', 'c54_low', 'c55_low', 'c56_low',\n",
       "       'c57_low', 'c58_low', 'c59_low', 'c60_low'],\n",
       "      dtype='object', length=206)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "import pandas as pd\n",
    "from lib import data_preprocessor\n",
    "\n",
    "# 데이터 csv를 dataFrame으로 변환\n",
    "# 데이터 경로는 ../data에 있는 data라는 이름이 들어간 csv 파일로 가정\n",
    "path = '../data/data_206_col.csv'\n",
    "df = data_preprocessor.transform_verilog_results_to_DataFrame(path, skiprows=0)\n",
    "normal_df, data_min, data_max = data_preprocessor.normalize_DataFrame(df)\n",
    "normal_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 80%의 학습 데이터와 20%의 테스트 데이터로 분할\n",
    "train_df, test_df = normal_df[:int(len(normal_df)*0.8)], normal_df[int(len(normal_df)*0.8):]\n",
    "\n",
    "# 데이터를 학습 데이터와 레이블로 분할하여 dataLoader로 변환\n",
    "input_feature = ['i' + str(i) + '_high' for i in range(1, 61)] + ['i' + str(i) + '_low' for i in range(1, 61)] + ['c' + str(i) + '_low' for i in range(1, 61)]\n",
    "output_feature = ['vth0', 'cit', 'mob_u0', 'mob_ua', 'mob_ub', 'mob_ug', 'nfactor', 'delta', 'kg', 'nlx', 'voff', 'cf', 'cgsl', 'cgso', 'cgdo', 'cgdl', 'clc', 'delvt', 'dwc', 'cjswg', 'csdesw', 'dlbg', 'dlc', 'moin']\n",
    "train_df.columns\n",
    "train_dl = data_preprocessor.transform_DataFrame_to_DataLoader(train_df[input_feature], train_df[output_feature], 128, True)\n",
    "\n",
    "# 테스트 데이터도 동일하게 변환\n",
    "test_dl = data_preprocessor.transform_DataFrame_to_DataLoader(test_df[input_feature], test_df[output_feature], 1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN 모델 학습\n",
    "\n",
    "from lib import model_training\n",
    "import lib.ANN as ANN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ann_model = ANN.ANN(input_feature.__len__(), output_feature.__len__())\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(ann_model.parameters(), lr=1e-5)\n",
    "ann_model, train_loss, val_loss = model_training.train_model(\n",
    "    ann_model, \n",
    "    train_dl, \n",
    "    100,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    test_dl,\n",
    "    1,\n",
    "    True\n",
    ")\n",
    "\n",
    "torch.save(ann_model.state_dict(), 'Model/ann_model_weights.pth')\n",
    "\n",
    "# 학습 결과 시각화\n",
    "plt.plot(train_loss, label='train')\n",
    "plt.plot(val_loss, label='val')\n",
    "plt.legend()\n",
    "plt.savefig('Model/ann_model_loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn을 이용하기 위한 데이터 변환\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "\n",
    "# 데이터를 학습 데이터와 레이블로 분할\n",
    "features = normal_df[input_feature]\n",
    "labels = normal_df[output_feature]\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터로 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest 모델 학습\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 랜덤 포레스트 회귀 모델 생성\n",
    "rf_model = RandomForestRegressor(n_estimators=50, random_state=42)  # n_estimators는 트리 개수, 조정 가능\n",
    "\n",
    "# 모델 학습\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터로 예측\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# 모델 평가 (MSE 사용)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "joblib.dump(rf_model, 'Model/random_forest_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBM 모델 학습\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "# GBM 모델 생성\n",
    "gbm_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "multi_output_gbm_model = MultiOutputRegressor(gbm_model)\n",
    "\n",
    "# 모델 학습\n",
    "multi_output_gbm_model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터로 예측\n",
    "y_pred = multi_output_gbm_model.predict(X_test)\n",
    "\n",
    "# 모델 평가 (MSE 사용)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "joblib.dump(multi_output_gbm_model, 'Model/gbm_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-D CNN 모델 학습\n",
    "\n",
    "from lib import model_training\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from lib.CNN_new import CNN\n",
    "\n",
    "cnn_model = CNN(input_feature.__len__(), output_feature.__len__())\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(cnn_model.parameters(), lr=1e-5)\n",
    "cnn_model, train_loss, val_loss = model_training.train_model(\n",
    "    cnn_model, \n",
    "    train_dl, \n",
    "    100,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    test_dl,\n",
    "    1,\n",
    "    True\n",
    ")\n",
    "\n",
    "torch.save(cnn_model.state_dict(), 'Model/cnn_model_weights.pth')\n",
    "\n",
    "# 학습 결과 시각화\n",
    "plt.plot(train_loss, label='train')\n",
    "plt.plot(val_loss, label='val')\n",
    "plt.legend()\n",
    "plt.savefig('Model/cnn_model_loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPR 모델 학습\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "# GPR 모델 생성\n",
    "gpr_model = GaussianProcessRegressor(kernel=RBF() + WhiteKernel(), random_state=42)\n",
    "multi_output_gpr_model = MultiOutputRegressor(gpr_model)\n",
    "\n",
    "# 모델 학습\n",
    "multi_output_gpr_model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터로 예측\n",
    "y_pred = multi_output_gpr_model.predict(X_test)\n",
    "\n",
    "# 모델 평가 (MSE 사용)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "joblib.dump(multi_output_gpr_model, 'Model/gpr_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM 모델 학습\n",
    "\n",
    "from lib import model_training\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from lib.LSTM import LSTM\n",
    "    \n",
    "lstm_model = LSTM(input_feature.__len__(), output_feature.__len__())\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(lstm_model.parameters(), lr=1e-5)\n",
    "lstm_model, train_loss, val_loss = model_training.train_model(\n",
    "    lstm_model, \n",
    "    train_dl, \n",
    "    100,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    test_dl,\n",
    "    1,\n",
    "    True\n",
    ")\n",
    "\n",
    "torch.save(lstm_model.state_dict(), 'Model/lstm_model_weights.pth')\n",
    "\n",
    "# 학습 결과 시각화\n",
    "plt.plot(train_loss, label='train')\n",
    "plt.plot(val_loss, label='val')\n",
    "plt.legend()\n",
    "plt.savefig('Model/lstm_model_loss.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
